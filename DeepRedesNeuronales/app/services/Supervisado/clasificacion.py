# -*- coding: utf-8 -*-
"""Clasificacion.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tl_z7s9zBQlsMMzNw7CYXXJ-MnH7AnK6

# Aprendizaje Supervisado : Clasificación

Para esta parte del laboratorio, utilizaremos el método de clasificación; cuyo objetivo será explorar el dataset entregado ( caso_estudio.csv ) , donde debemos analizar y resolver las preguntas dejadas a continuación:

1. Analice el dataset entregado e identifique que encontró.
2. Para este estudio de clasificación, debemos realizarlo con los siguientes casos:
  
  2.1. Utilice todos los datos del dataset, si encuentra datos que no cuadran proponga alguna solución para poder dar solución al problema ( para este punto no borren las filas )
  
  2.2 Utilice los siguientes porcentajes de datos del dataset: 30% , 50% , 70% , 90% ¿ qué diferencias encuentra a la hora de realizar el estudio del dataset ?

  2.2.1 ¿ Qué cambios observa en los datos de entrenamiento y validación ? ¿ corresponde al 25% de los datos y 75% de los datos especificamente ? , argumente su respuesta.

  2.2.2 Documente los tiempos obtenidos y el porcentaje de precisión y realice una interpretación de los resultados obtenidos.

  2.2.3. Dibuje la matriz de confusión de los 2.2 e interprete los resultados de la misma

  2.2.4 ¿ Cuál porcentaje de uso del dataset considera que es ideal para el estudio ? , argumente su respuesta.

Pueden utilizar el codigo como crean conveniente , y pueden cambiar las variables que crean necesarias para dar solución al ejercicio.

  Fuentes para consultar:

  https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html
  https://scikit-learn.org/stable/modules/model_evaluation.html

  https://scikit-learn.org/stable/modules/preprocessing.html
"""

# Manipulación de datos
import pandas as pd
# Operaciones numéricas
import numpy as np
# Para medición del tiempo que toma ejecutar los procesos
from time import time
# Para separar datos de entrenamiento y prueba
from sklearn.model_selection import train_test_split
# Librería para SVM
from sklearn.svm import SVC
# Medición de precisión
from sklearn.metrics import accuracy_score, confusion_matrix
# Generar gráficos
import matplotlib.pyplot as plt
#subir archivo
from google.colab import files
#visualizaciòn netamente estadistica
import seaborn as sns
#calculador del estandar
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score
# Generar gráficos
import matplotlib.pyplot as plt

#Importa archivos desde la computadora
uploaded = files.upload()

# Leemos el set de datos y lo cargamos en la variable df, que es un DataFrame de pandas
diabetes_df = pd.read_csv('caso_estudio.csv')
# Mostrar información sobre el set de datos

diabetes_df.info()  # Identificar columnas con valores nulos

# Para los valores nulos, reemplazarlos con la media de la columna
diabetes_df.fillna(diabetes_df.mean(), inplace=True)


# Transformar los valores que parecen inadecuados
# Ejemplo: reemplazar valores 0 en columnas como 'Glucose', 'BloodPressure' que no pueden ser 0
for column in ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']:
    diabetes_df[column] = diabetes_df[column].replace(0, diabetes_df[column].mean())

# Mostrar un resumen para confirmar los ajustes
print(diabetes_df.describe())

# Crearemos un nuevo df llamado X (notar mayus) con las columnas de características
# Se obtiene generando una lista de columnas del df a utilizar
lista_caract = [
    'Pregnancies',
    'Glucose',
    'BloodPressure',
    'SkinThickness',
    'Insulin',
    'BMI',
    'DiabetesPedigreeFunction',
    'Age'
]
# Luego tomando esa lista del df original
X = diabetes_df[lista_caract]
# Mostraremos los primeros cinco registros para conocer cómo se compone X
X.head(20)

# Utilizaremos el mismo procedimiento para generar y
lista_etiq = ['Outcome']
y = diabetes_df[lista_etiq]
y.head(20)

# Separar en datos de entrenamiento y datos de prueba
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.25)

# Mostraremos la cantidad de datos a utilizar para el entrenamiento
X_train.shape
y_train.shape

# Luego, la cantidad de datos a utilizar para validar
X_test.shape
y_test.shape

# Definimos una función para entrenar y evaluar el modelo con diferentes porcentajes de datos
def evaluar_porcentaje(porcentaje, X, y):
    n = int(len(X) * (porcentaje / 100))

    # Seleccionar los primeros n registros del dataset
    X_subset = X.head(n)
    y_subset = y.head(n)

    # Separar datos de entrenamiento y prueba (25% validación, 75% entrenamiento)
    X_train, X_test, y_train, y_test = train_test_split(X_subset, y_subset, test_size=0.25)

    # Entrenar el modelo SVM
    clf = SVC()
    inicio_entrenamiento = time()
    clf.fit(X_train, y_train.values.ravel())
    tiempo_entrenamiento = time() - inicio_entrenamiento

    # Realizar predicciones
    inicio_prediccion = time()
    y_pred = clf.predict(X_test)
    tiempo_prediccion = time() - inicio_prediccion

    # Calcular precisión
    precision = accuracy_score(y_test, y_pred)

    # Generar matriz de confusión
    matriz_confusion = confusion_matrix(y_test, y_pred)

    return {
        'porcentaje': porcentaje,
        'n_datos': n,
        'tiempo_entrenamiento': tiempo_entrenamiento,
        'tiempo_prediccion': tiempo_prediccion,
        'precision': precision,
        'matriz_confusion': matriz_confusion
    }

# Evaluar para diferentes porcentajes
resultados = []
for porcentaje in [30, 50, 70, 90, 100]:
    resultado = evaluar_porcentaje(porcentaje, X, y)
    resultados.append(resultado)

# Mostrar resultados
for res in resultados:
    print(f"Porcentaje: {res['porcentaje']}%")
    print(f"Datos utilizados: {res['n_datos']}")
    print(f"Tiempo de entrenamiento: {res['tiempo_entrenamiento']:.4f} segundos")
    print(f"Tiempo de predicción: {res['tiempo_prediccion']:.4f} segundos")
    print(f"Precisión: {res['precision']:.4f}")
    print(f"Matriz de confusión:\n{res['matriz_confusion']}\n")

# Definició del modelo que llamaremos clf
clf = SVC()

# Guardamos el registro del momento en el que empezamos el entrenamiento
hora_inicio = time()

# Iniciamos el entrenamiento ejecutando el metodo fit
# Los valores que enviamos son los valores de X y y
#
# El .ravel() que final de y.values es un pequeño truco para cambiar su forma
# esto permite convertir una matriz de dos dimensiones en una sola dimesión,
# con ello, cada elemento de esta nueva matriz corresponde a un registro de X
clf.fit(X_train.values, y_train.values.ravel())

# Imprimimos el tiempo tomado para el entrenamiento
print("Entrenamiento terminado en {} segundos".format(time() - hora_inicio))

# Otra vez guardaremos registro del tiempo que nos toma crear esta predicción
hora_inicio = time()
# Iniciamos la predicción con nuestra X de prueba
y_pred = clf.predict(X_test)
# Mostramos el tiempo tomado para la predicción
print("Predicción terminada en {} segundos".format(time() - hora_inicio))

# Evaluamos la precisión
prec = accuracy_score(y_test, y_pred)
print(prec)

# La función confusion_matrix recibe las "respuestas correctas" y nuestras predicciones
# genera una matriz que indica, para cada clase, la cantidad de predicciones correctas e incorrectas
conf_diabetes = confusion_matrix(y_test, y_pred)
conf_diabetes

# Otra vez guardaremos registro del tiempo que nos toma crear esta predicción
hora_inicio = time()
# Iniciamos la predicción con nuestra X de prueba
y_pred = clf.predict(X_test)
# Mostramos el tiempo tomado para la predicción
print("Predicción terminada en {} segundos".format(time() - hora_inicio))

# Graficar precisión y tiempos
import matplotlib.pyplot as plt

porcentajes = [res['porcentaje'] for res in resultados]
precisiones = [res['precision'] for res in resultados]
tiempos_entrenamiento = [res['tiempo_entrenamiento'] for res in resultados]
tiempos_prediccion = [res['tiempo_prediccion'] for res in resultados]

# Precisión
plt.figure(figsize=(10, 6))
plt.plot(porcentajes, precisiones, marker='o', label='Precisión')
plt.xlabel('Porcentaje del dataset')
plt.ylabel('Precisión')
plt.title('Precisión vs Porcentaje del dataset')
plt.legend()
plt.show()

# Tiempos
plt.figure(figsize=(10, 6))
plt.plot(porcentajes, tiempos_entrenamiento, marker='o', label='Tiempo de entrenamiento')
plt.plot(porcentajes, tiempos_prediccion, marker='o', label='Tiempo de predicción')
plt.xlabel('Porcentaje del dataset')
plt.ylabel('Tiempo (segundos)')
plt.title('Tiempos de entrenamiento y predicción')
plt.legend()
plt.show()

def plot_cm(cm, classes):
    """Esta función se encarga de generar un gráfico con nuestra matriz de confusión.
    cm es la matriz generada por confusion_matrix
    classes es una lista que contiene las posibles clases que puede predecir nuestro modelo
    """
    plt.imshow(cm, cmap=plt.cm.Blues)
    plt.title('Matriz de confusión')
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)
    thresh = cm.max() / 2.
    for indice_fila, fila in enumerate(cm):
        for indice_columna, columna in enumerate(fila):
            if cm[indice_fila, indice_columna] > thresh:
                color = "white"
            else:
                color = "black"
            plt.text(
                indice_columna,
                indice_fila,
                cm[indice_fila, indice_columna],
                color=color,
                horizontalalignment="center"
            )
    plt.ylabel("Valores reales")
    plt.xlabel("Valores calculados")
    plt.show()

# Generamos el gráfico llamando la función que creamos y enviando los parámetros
# cm = nuestra matriz de confusión (conf_diabetes)
# classes = las clases a predecir (si tienen diabetes o no)
for res in resultados:
    print(f"Matriz de confusión para {res['porcentaje']}% del dataset:")
    plot_cm(res['matriz_confusion'], ['No diabetes', 'Sí diabetes'])